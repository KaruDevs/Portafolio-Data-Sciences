# -*- coding: utf-8 -*-
"""ConsolidadoM6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O55WaekTE3_iTvTa_aMsfskp5zR-Clnd
"""

#  1. Importaci贸n de librer铆as
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay
from sklearn.preprocessing import label_binarize

#  2. Carga y exploraci贸n de datos
df = pd.read_csv("cambio_climatico_agricultura.csv")

print(" Vista general del dataset:")
print(df.head())
print("\n Estad铆sticas descriptivas:")
print(df.describe())

# Visualizaci贸n
sns.pairplot(df.drop(columns=["Pa铆s"]))
plt.suptitle("Distribuci贸n de variables clim谩ticas y producci贸n", y=1.02)
plt.show()

#  Detecci贸n de outliers
sns.boxplot(data=df.drop(columns=["Pa铆s"]))
plt.title("Boxplot de variables num茅ricas")
plt.show()

#  3. Preprocesamiento
X = df.drop(columns=["Pa铆s", "Producci贸n_alimentos"])
y = df["Producci贸n_alimentos"]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Divisi贸n de datos
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

#  4. Modelos de regresi贸n
def evaluar_regresion(modelo, nombre):
    modelo.fit(X_train, y_train)
    y_pred = modelo.predict(X_test)
    print(f"\n Resultados de {nombre}:")
    print(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")
    print(f"MSE: {mean_squared_error(y_test, y_pred):.2f}")
    print(f"R虏: {r2_score(y_test, y_pred):.2f}")

evaluar_regresion(LinearRegression(), "Regresi贸n Lineal")
evaluar_regresion(DecisionTreeRegressor(random_state=42), "rbol de Decisi贸n")
evaluar_regresion(RandomForestRegressor(random_state=42), "Random Forest")

#  5. Clasificaci贸n por impacto clim谩tico
# Categorizaci贸n basada en terciles
df["Impacto_climatico"] = pd.qcut(df["Producci贸n_alimentos"], q=3, labels=["Alto", "Medio", "Bajo"])

X_clf = df.drop(columns=["Pa铆s", "Producci贸n_alimentos", "Impacto_climatico"])
y_clf = df["Impacto_climatico"]

X_clf_scaled = scaler.fit_transform(X_clf)
Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_clf_scaled, y_clf, test_size=0.2, random_state=42)

# Funci贸n de evaluaci贸n de clasificaci贸n
def evaluar_clasificacion(modelo, nombre):
    modelo.fit(Xc_train, yc_train)
    yc_pred = modelo.predict(Xc_test)
    print(f"\n Clasificaci贸n con {nombre}:")
    print(confusion_matrix(yc_test, yc_pred))
    print(classification_report(yc_test, yc_pred))

evaluar_clasificacion(KNeighborsClassifier(), "KNN")
evaluar_clasificacion(DecisionTreeClassifier(random_state=42), "rbol de Decisi贸n")
evaluar_clasificacion(SVC(probability=True), "SVM")

# ROC-AUC para SVM (multiclase)
svc_model = SVC(probability=True)
svc_model.fit(Xc_train, yc_train)
yc_proba = svc_model.predict_proba(Xc_test)

# Get the class labels from the trained model
classes = svc_model.classes_

plt.figure(figsize=(8, 6))
for i, class_name in enumerate(classes):
    # Binarize the true labels for the current class
    y_true_bin = (yc_test == class_name).astype(int)

    # Check if the binarized true labels have more than one unique value
    if len(np.unique(y_true_bin)) > 1:
        # Plot the ROC curve for the current class
        RocCurveDisplay.from_predictions(y_true_bin, yc_proba[:, i], name=f"ROC curve for {class_name} (vs rest)")
    else:
        print(f"Skipping ROC curve for class '{class_name}' as it does not have enough samples in the test set to compute ROC.")


plt.plot([0, 1], [0, 1], 'k--', label='Chance level (AUC = 0.5)')
plt.axis('square')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curva ROC - SVM (Uno contra el resto)')
plt.legend()
plt.show()


#  6. Optimizaci贸n de modelos
# Grid Search para Random Forest
param_grid_rf = {
    "n_estimators": [50, 100, 200],
    "max_depth": [None, 5, 10]
}
grid_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5)
grid_rf.fit(X_train, y_train)
print("\n Mejor configuraci贸n Random Forest:", grid_rf.best_params_)

# Regularizaci贸n con Ridge y Lasso
evaluar_regresion(Ridge(alpha=1.0), "Ridge")
evaluar_regresion(Lasso(alpha=0.1), "Lasso")

#  7. Conclusiones
print("\n Reflexi贸n final:")
print("""
Los modelos de Random Forest y Ridge ofrecieron mejor desempe帽o en regresi贸n,
mientras que SVM mostr贸 buena capacidad de clasificaci贸n. La variabilidad clim谩tica
impacta de forma significativa en la producci贸n agr铆cola, especialmente en pa铆ses con
alta frecuencia de sequ铆as y cambios extremos en precipitaciones. Estos hallazgos
pueden orientar pol铆ticas de seguridad alimentaria y adaptaci贸n clim谩tica.
""")