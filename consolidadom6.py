# -*- coding: utf-8 -*-
"""ConsolidadoM6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O55WaekTE3_iTvTa_aMsfskp5zR-Clnd
"""

#  1. Importación de librerías
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay
from sklearn.preprocessing import label_binarize

#  2. Carga y exploración de datos
df = pd.read_csv("cambio_climatico_agricultura.csv")

print(" Vista general del dataset:")
print(df.head())
print("\n Estadísticas descriptivas:")
print(df.describe())

# Visualización
sns.pairplot(df.drop(columns=["País"]))
plt.suptitle("Distribución de variables climáticas y producción", y=1.02)
plt.show()

#  Detección de outliers
sns.boxplot(data=df.drop(columns=["País"]))
plt.title("Boxplot de variables numéricas")
plt.show()

#  3. Preprocesamiento
X = df.drop(columns=["País", "Producción_alimentos"])
y = df["Producción_alimentos"]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# División de datos
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

#  4. Modelos de regresión
def evaluar_regresion(modelo, nombre):
    modelo.fit(X_train, y_train)
    y_pred = modelo.predict(X_test)
    print(f"\n Resultados de {nombre}:")
    print(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")
    print(f"MSE: {mean_squared_error(y_test, y_pred):.2f}")
    print(f"R²: {r2_score(y_test, y_pred):.2f}")

evaluar_regresion(LinearRegression(), "Regresión Lineal")
evaluar_regresion(DecisionTreeRegressor(random_state=42), "Árbol de Decisión")
evaluar_regresion(RandomForestRegressor(random_state=42), "Random Forest")

#  5. Clasificación por impacto climático
# Categorización basada en terciles
df["Impacto_climatico"] = pd.qcut(df["Producción_alimentos"], q=3, labels=["Alto", "Medio", "Bajo"])

X_clf = df.drop(columns=["País", "Producción_alimentos", "Impacto_climatico"])
y_clf = df["Impacto_climatico"]

X_clf_scaled = scaler.fit_transform(X_clf)
Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_clf_scaled, y_clf, test_size=0.2, random_state=42)

# Función de evaluación de clasificación
def evaluar_clasificacion(modelo, nombre):
    modelo.fit(Xc_train, yc_train)
    yc_pred = modelo.predict(Xc_test)
    print(f"\n Clasificación con {nombre}:")
    print(confusion_matrix(yc_test, yc_pred))
    print(classification_report(yc_test, yc_pred))

evaluar_clasificacion(KNeighborsClassifier(), "KNN")
evaluar_clasificacion(DecisionTreeClassifier(random_state=42), "Árbol de Decisión")
evaluar_clasificacion(SVC(probability=True), "SVM")

# ROC-AUC para SVM (multiclase)
svc_model = SVC(probability=True)
svc_model.fit(Xc_train, yc_train)
yc_proba = svc_model.predict_proba(Xc_test)

# Get the class labels from the trained model
classes = svc_model.classes_

plt.figure(figsize=(8, 6))
for i, class_name in enumerate(classes):
    # Binarize the true labels for the current class
    y_true_bin = (yc_test == class_name).astype(int)

    # Check if the binarized true labels have more than one unique value
    if len(np.unique(y_true_bin)) > 1:
        # Plot the ROC curve for the current class
        RocCurveDisplay.from_predictions(y_true_bin, yc_proba[:, i], name=f"ROC curve for {class_name} (vs rest)")
    else:
        print(f"Skipping ROC curve for class '{class_name}' as it does not have enough samples in the test set to compute ROC.")


plt.plot([0, 1], [0, 1], 'k--', label='Chance level (AUC = 0.5)')
plt.axis('square')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curva ROC - SVM (Uno contra el resto)')
plt.legend()
plt.show()


# 🔧 6. Optimización de modelos
# Grid Search para Random Forest
param_grid_rf = {
    "n_estimators": [50, 100, 200],
    "max_depth": [None, 5, 10]
}
grid_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5)
grid_rf.fit(X_train, y_train)
print("\n Mejor configuración Random Forest:", grid_rf.best_params_)

# Regularización con Ridge y Lasso
evaluar_regresion(Ridge(alpha=1.0), "Ridge")
evaluar_regresion(Lasso(alpha=0.1), "Lasso")

#  7. Conclusiones
print("\n Reflexión final:")
print("""
Los modelos de Random Forest y Ridge ofrecieron mejor desempeño en regresión,
mientras que SVM mostró buena capacidad de clasificación. La variabilidad climática
impacta de forma significativa en la producción agrícola, especialmente en países con
alta frecuencia de sequías y cambios extremos en precipitaciones. Estos hallazgos
pueden orientar políticas de seguridad alimentaria y adaptación climática.
""")